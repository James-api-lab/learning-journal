# ğŸ§± Week 5 Learning Journal â€” Flask CRUD + Persistence
*Learning APIs Project*

---

## ğŸ—“ Week Overview
**Goal:** Learn how APIs store, read, update, and delete data using Flask + SQLite + SQLAlchemy.

---

## ğŸ§© Day 1 â€” Persistence Foundations
**Focus:** What does â€œsaving dataâ€ actually mean?

**What I did**
- Created project folder and virtual env  
- Installed Flask, SQLAlchemy, dotenv, pytest  
- Verified `/health` route  
- Fixed SQLite path errors with absolute path logic  

**What I learned**
- Persistence = data living beyond a single run  
- ORMs translate Python â†” SQL so you donâ€™t write raw queries  
- `commit()` makes data permanent  

**Challenges**
- â€œUnable to open database fileâ€ â†’ fixed via `config.py` path builder  
- PowerShell curl alias confusion  

**Next Step**
- Implement Create + Read routes tomorrow

## ğŸ§© Day 2 â€” Create + Read Deep Dive

**Focus:** Adding validation and data integrity to the API.

**What I did**
- Enhanced `/records` POST to validate input fields (`city`, `temp`, `humidity`).
- Added consistent JSON error responses for invalid data.
- Tested different POST scenarios in PowerShell using `Invoke-WebRequest` and `Invoke-RestMethod`.

**What I learned**
- Validation is what separates hobby projects from production code.
- PowerShell and `curl.exe` handle JSON quoting differently â€” an important cross-platform lesson.
- Error responses should be predictable (always JSON, always include an `error` key).

**Challenges**
- Frustration with JSON quoting and `curl` syntax.
- Understanding why Flask rejected certain requests helped clarify how request bodies are parsed.
- The learning felt slow, but it reinforced core API behaviors (status codes, contracts).

**Next Step**
- Implement `PUT` and `DELETE` routes to complete the CRUD cycle.
- Add safeguards so updates and deletions are intentional and confirmed.

**Mood Check**
Slightly underwhelmed today â€” this part feels repetitive, but itâ€™s the groundwork for professional-grade APIs. Iâ€™m getting more confident with Flask, SQLAlchemy, and structured testing.

## Day 3 â€” Update & Delete (CRUD U/D)

**What I built**
- Added `PUT /records/<id>` to update fields (`city`, `temp`, `humidity`).
- Added `DELETE /records/<id>` to remove a record.
- Added a global `@app.errorhandler(404)` so **all** 404s return JSON (no HTML pages).

**Why it matters**
- Clients need predictable error shapes. JSON 404s make programmatic handling easy.
- `db.session.commit()` is the â€œsave pointâ€ for dataâ€”mirrors how `git commit` saves code.
- Idempotence: `DELETE` can be safely retried; `PUT` leads to a known final state.

**What I tested**
- Update success:
  - `PUT /records/1` with `{"city":"Seattle (Updated)","temp":19}` â†’ `200` + updated JSON.
- Delete success:
  - `DELETE /records/<id>` for an existing id â†’ `200` + confirmation message.
- Missing resource (defensive cases):
  - `PUT /records/999999` â†’ `404` + `{"error":"Not Found"}` (or `{"error":"record not found"}` if from route).
  - `DELETE /records/999999` â†’ `404` + JSON error.
- Verified collection:
  - `GET /records/` shows current rows.

**Mental model connections**
- CRUD in the API â†” change management in Git:
  - Update data â†’ `PUT` â†” edit file â†’ `git commit`
  - Delete data â†’ `DELETE` â†” `git rm` â†’ `git commit`
- Route not found vs resource not found:
  - Route-miss 404 (framework) now returns JSON via the global handler.
  - Resource-miss 404 (handled in route) also returns JSON consistently.

**Gotchas I learned**
- Restart the dev server after editing routes (so Flask loads new code).
- Test with `curl -i` to see status + `Content-Type` and confirm JSON responses.

Mood check: generally pretty furstrated but mainly because git commands. 


## Day 4 â€” Stats, Seeding, SQL Thinking
- Wrote idempotent `scripts/seed.py` (safe to run multiple times).
- Verified `/records/stats` aggregates with `func.avg`, `func.count` (DB does the math).
- Added tests for empty + populated DB; configured pytest to find `app`.
- Takeaway: aggregate in SQL, serve in JSON; keep seeding reproducible.

## ğŸ§± Week 5 Day 5 â€” Logging & Error Hygiene  

**Goal:**  
Make the API production-ready by adding *visibility* (logs) and *predictability* (consistent JSON errors).

---

### ğŸ§  What I Learned  

- **Logging is observability.**  
  Every request now records its method, path, status, IP, and duration in `logs/app.log`.  
  I can finally *see* whatâ€™s happening inside my APIâ€”like a flight recorder for Flask.

- **Error consistency builds trust.**  
  Both `404` and `500` now return JSON objects instead of raw HTML, e.g.:  
  ```json
  {"error": "Not Found"}
  {"error": "Internal Server Error"}

---

## ğŸª Guided Reflection Addendum â€” Week 5 Day 5  

I didnâ€™t feel totally confident answering the reflection questions at first.  
But after walking through what each idea *really means*, I can see how these concepts connect.

---

### 1ï¸âƒ£ Why is logging critical once an API leaves your local machine?  
Because when my API runs on another computer or in the cloud, I canâ€™t just `print()` things to see whatâ€™s happening.  
Logging is my visibility.  
It shows **who** hit my endpoints, **what** they did, and **how** my system responded.  
If something breaks or slows down, the logs are the story of what happened.  
They turn an invisible process into something observable and fixable.

---

### 2ï¸âƒ£ Whatâ€™s the danger of returning HTML error pages to JSON clients?  
APIs talk to code, not humans.  
If I send back an HTML error page, a front-end or automation client canâ€™t parse it â€” it just fails.  
By always returning JSON like `{"error": "Not Found"}`, I make my APIâ€™s behavior predictable.  
Thatâ€™s what lets other programs, mobile apps, or even future versions of my own app trust the interface.

---

### 3ï¸âƒ£ How could structured logs (JSON format) make analytics easier later?  
Right now, my logs are readable by me, but not easily by machines.  
If I switched to structured JSON logs â€” one JSON object per line â€” I could feed them into a dashboard, filter them by route or response time, or visualize errors per day.  
That turns logs from â€œtext to scanâ€ into **data to analyze**.

---

### 4ï¸âƒ£ How will I extend this when I deploy to a cloud host?  
Instead of writing to a file on disk, my Flask or FastAPI app would send logs to a cloud logger such as CloudWatch, Papertrail, or Supabase analytics.  
The exact tool changes, but the principles I practiced â€” rotation, structured messages, consistent error JSON â€” stay the same.  
Everything I built locally is the foundation for observability and stability in production.

---

### ğŸ§­ Takeaway  
This week wasnâ€™t just about CRUD.  
It was about learning to *see inside* my API â€” understanding that logs, errors, and tests are what separate **a script that works** from **a service that can be trusted**.  
Iâ€™m not just running code anymore; Iâ€™m running a system.

---

## ğŸ—“ï¸ What I Did
Today I introduced automated testing into my Flask CRUD app using `pytest` and Flaskâ€™s `test_client`.
At first, my delete test failed with a *â€œworking outside of application contextâ€* error â€” this forced me to understand how Flask manages database sessions through its **application context**.
I rewrote the tests to be **API-driven** (using real HTTP requests) instead of touching the database directly, and everything passed.

---

## ğŸ” What I Learned

| Concept | Description |
|----------|--------------|
| **App Context** | Flask isolates resources like `db.session` inside an *application context*. Anything outside that context wonâ€™t know which app or request it belongs to. |
| **Flask Test Client** | Lets me call routes (`POST /records`, `DELETE /records/1`) inside tests without running the actual server. |
| **API-Driven Tests** | Simulate real client behavior instead of directly modifying the database. This is closer to how the API will be used in production. |
| **Test Isolation** | Each test starts with a clean database using `db.drop_all()` + `db.create_all()`, so results are consistent. |
| **Safety Net for Refactors** | With tests in place, I can change code confidently and prove that endpoints still behave correctly. |

---

## ğŸ§© Why It Matters
This was the first time I truly *trusted* my API.
Instead of manually cURLing every route, I can now run one command (`pytest -q`) and instantly see if anything broke.
It also built intuition for how frameworks like FastAPI or Django manage their own contexts â€” the same concepts will carry over.

Automated tests are what turn scripts into software.

---

## ğŸ’¡ Key Takeaways
- Every route can be tested like a black-box system: send a request, assert on the JSON.  
- The application context is the invisible boundary that keeps Flask apps predictable.  
- Writing tests makes debugging 10Ã— faster because failures point exactly to broken assumptions.  
- Good tests donâ€™t just verify code â€” they **teach** you how your system behaves.

---

## ğŸ”— How It Connects
In future projects:
- **PathTwo** â†’ verify financial inputs calculate the right savings rates.  
- **Recap Games** â†’ test that recap generation endpoints return structured JSON before rendering UI.  
- **Garden Companion** â†’ ensure POSTing a new plant actually persists across sessions.  

All of them will reuse the same pattern you built today:  
> `pytest + test_client â†’ confidence + speed.`


## Week 5 - Day 6

## ğŸ—“ï¸ What I Did
Today I introduced automated testing into my Flask CRUD app using `pytest` and Flaskâ€™s `test_client`.
At first, my delete test failed with a *â€œworking outside of application contextâ€* error â€” this forced me to understand how Flask manages database sessions through its **application context**.
I rewrote the tests to be **API-driven** (using real HTTP requests) instead of touching the database directly, and everything passed.

---

## ğŸ” What I Learned

| Concept | Description |
|----------|--------------|
| **App Context** | Flask isolates resources like `db.session` inside an *application context*. Anything outside that context wonâ€™t know which app or request it belongs to. |
| **Flask Test Client** | Lets me call routes (`POST /records`, `DELETE /records/1`) inside tests without running the actual server. |
| **API-Driven Tests** | Simulate real client behavior instead of directly modifying the database. This is closer to how the API will be used in production. |
| **Test Isolation** | Each test starts with a clean database using `db.drop_all()` + `db.create_all()`, so results are consistent. |
| **Safety Net for Refactors** | With tests in place, I can change code confidently and prove that endpoints still behave correctly. |

---

## ğŸ§© Why It Matters
This was the first time I truly *trusted* my API.
Instead of manually cURLing every route, I can now run one command (`pytest -q`) and instantly see if anything broke.
It also built intuition for how frameworks like FastAPI or Django manage their own contexts â€” the same concepts will carry over.

Automated tests are what turn scripts into software.

---

## ğŸ’¡ Key Takeaways
- Every route can be tested like a black-box system: send a request, assert on the JSON.  
- The application context is the invisible boundary that keeps Flask apps predictable.  
- Writing tests makes debugging 10Ã— faster because failures point exactly to broken assumptions.  
- Good tests donâ€™t just verify code â€” they **teach** you how your system behaves.

---

## ğŸ”— How It Connects
In future projects:
- **PathTwo** â†’ verify financial inputs calculate the right savings rates.  
- **Recap Games** â†’ test that recap generation endpoints return structured JSON before rendering UI.  
- **Garden Companion** â†’ ensure POSTing a new plant actually persists across sessions.  

All of them will reuse the same pattern you built today:  
> `pytest + test_client â†’ confidence + speed.`
