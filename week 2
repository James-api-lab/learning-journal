### Day 6 — Refactor into Functions (and make it usable)

**What I built**
- Created a working `weather_cli.py` that accepts city names as CLI args.
- Centralized `.env` loading next to the script with `Path(__file__).with_name(".env")` so it runs reliably from any folder.
- Updated `README.md` with exact run commands from root vs inside `week2/`.

**What I learned**
- **Functions → reuse**: wrapping API logic in `get_weather(city)` lets me call it from a CLI, scheduler, or later a web endpoint.
- **Env loading matters**: `load_dotenv()` depends on the *working directory*; pointing to the file explicitly avoids “missing key” bugs.
- **Paths & shells**: PowerShell ≠ Unix. Use `New-Item`/`Set-Content` instead of `mkdir -p`/`printf`. Also, `cd` only moves into folders (not files).
- **Run context**: VS Code’s “Run” uses an absolute path; terminal commands are relative to the current folder—hence `python week2/...` vs `python weather_one_city.py`.
- **Git paths**: `git add` paths are relative to the current directory. Being inside `week2/` means don’t prefix `week2/` again.

**Snags & fixes**
- Error: “Missing OPENWEATHER_API_KEY” → fixed by explicitly loading `week2/.env` with `Path(__file__).with_name(".env")`.
- Error: file not found when running from repo root → ran with the correct relative path (`python week2/weather_one_city.py`) or `cd week2` first.
- SyntaxError from `@'`…`'@` → realized those are PowerShell here-string markers and must not end up in `.py` files.

**Finish Log**
> I refactored the weather call into a reusable function and built a CLI that prints live temps for any city. Env loading and paths are now reliable.

### Day 7 — Weather CLI + Daily Logger

**What I built**
- Finalized a Weather CLI that accepts city args and prompts with no args.
- Added `log_weather_daily.py` that appends one row per city per day into `data/weather_log.csv`, with simple de-dupe.

**What I learned**
- Small, focused functions make CLIs and schedulers trivial to build on.
- Explicit `.env` loading with `Path(__file__).with_name(".env")` removes “where am I running?” issues.
- Appending + de-dupe is enough to create reliable time-series data for charts.

**Finish Log**
> I shipped a working CLI and a daily logger that builds a weather history automatically.

### Day 8 — Visualize & Share (Charts)

**What I built**
- `chart_weather.py` that reads `data/weather_log.csv` and saves `data/weather_chart.png`.
- Tweaked plotting to show single points (scatter) and tightened axes so early data is visible.

**What I learned**
- One point per city looks “empty” on a line chart; show a dot and tighten the x/y range.
- Matplotlib basics: `plt.plot` vs `plt.scatter`, date formatting with `matplotlib.dates`, and setting axis limits.
- File paths matter: writing/reading from a consistent `data/` folder makes scripts chain nicely.

**Snags & fixes**
- Empty-looking plot → added scatter for single-point series + axis padding.
- `NameError: plt not defined` → restored `import matplotlib.pyplot as plt` and `matplotlib.dates`.
- File name mismatch (`chart-weather.py` vs `chart_weather.py`) → ran the correct path.

**Finish Log**
> Generated and committed `weather_chart.png` from my daily CSV; chart now renders clearly even with sparse data.

### Day 9 — Make It Production-ish (Sessions, Retries, Timeouts)

**What I built**
- `http_utils.make_session()` to create a `requests.Session` with retries + exponential backoff.
- Updated `weather_cli.py` to use a shared session, a 10s timeout, clearer network/auth/404 errors, and correct °F/°C labels.

**What I learned**
- **Sessions** reuse connections → faster and less flaky than fresh `requests.get()` each time.
- **Retries + backoff** auto-handle temporary 429/500/503 errors.
- **Timeouts** prevent scripts from hanging indefinitely.
- Printing the right unit label matters (imperial vs metric).
- Avoid DEBUG logs in prod—they can leak secrets (keys in URLs).

**Finish Log**
> I hardened the CLI: added session reuse, retries, and timeouts, fixed unit labels, and verified friendly errors. Ready for daily use.

### Day 10 — CLI Flags + Structured Logging

**What I built**
- Added `argparse` flags: `--units`, `--timeout`, `--retries`, `--backoff`, and `--cities-file`.
- Wired a tuned `requests.Session` (retries + backoff) from `http_utils.py`.
- Rotating file logs at `logs/weather-cli.log` with timestamps.

**What I learned**
- `argparse` turns command text into validated variables (with `--help` for free).
- Sessions reuse connections; retries/backoff make the CLI resilient.
- Timeouts prevent hangs; rotating logs give lightweight observability.

**Finish Log**
> I turned the script into a real CLI: configurable flags, robust HTTP, and a run log.

### Day 11 — Machine-Readable Output + Controlled Logging

**What I built**
- `--json` flag: prints one JSON object per city.
- `--csv-out` with `.env` default (`CSV_OUT=data/weather_log.csv`): append this run to the main log.
- De-dupe when writing to `weather_log.csv` (skip same `(date, city)`).
- Chart script now reads `temp` + `units` and auto-labels °C/°F.

**What I learned**
- Separate data from presentation: same fetch can output text or JSON.
- Env-driven defaults (CSV_OUT/UNITS) keep commands short but configurable.
- De-dupe at the write layer prevents messy time series.

**Finish Log**
> I added JSON output and CSV append with duplicate protection, and confirmed the chart auto-labels units from the log.


### Day 12 — Automation

**What I built**
- Scheduled `log_weather_daily.py` via Windows Task Scheduler using my venv’s Python.
- Locked units in `.env` and set `CSV_OUT` to the main log.

**What I learned**
- Use absolute paths + “Start in” so scheduled jobs find files/venv.
- Keep generated data out of Git; code-only commits are cleaner.

**Finish Log**
> Daily logging now runs automatically; the chart updates cleanly from a consistent, unit-locked CSV.


### Day 13 — Package + One-Command Runner

**What I built**
- Packaged the app with `pyproject.toml` and added a console script: `weather`.
- Created `weather-daily` runner to log then generate the chart in one command.
- Cleaned repo structure (all Python under `week2/`, ignore generated logs/data).

**What I learned**
- Entry points map `command → module:function` so the CLI is importable/testable.
- Editable installs (`pip install -e .`) let me iterate without reinstalling.
- Keeping generated artifacts out of Git keeps history clean and diffs small.

**Finish Log**
> I can now run `weather …` anywhere in my venv and `weather-daily` to log + chart in one step.

### Day 14 — Faster runs + smarter calls

**What I built**
- Parallel fetch with `--max-workers` (ThreadPoolExecutor) for multiple cities.
- Same-day, per-units cache with `--cache-day` in `data/cache/YYYY-MM-DD_units.json`.
- Kept CSV de-dupe and logging logic intact.

**What I learned**
- Weather calls are I/O-bound; threads overlap network waits to cut wall time.
- requests.Session isn’t thread-safe; use one per worker.
- Tiny JSON caches slash repeat work and help stay under rate limits.

**Finish Log**
> Parallelized multi-city fetches and added a same-day cache. Re-runs are near-instant and API usage is lower.

